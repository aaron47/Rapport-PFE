\chapter{Approches Proposées}
\etocsettocstyle{\section*{Sommaire}}{}
\localtableofcontents

\newpage
\section{Introduction}
\noindent
Dans ce chapitre on va explorer les différentes solutions potentielles et les différentes approches qu'on a pris pour améliorer la recherche dans notre projet. Nous aborderons chacune des technologies utilisées en expliquant leurs fonctions principales, leurs utilisations courantes et leurs avantages. Nous discuterons également de l'importance de ces outils dans le domaine de l'analyse du texte et du traitement du langage naturel. En comprenant ces différentes approches, nous serons en mesure d'explorer en détail leurs fonctionnalités spécifiques et leur pertinence pour notre projet de PFE.

\section{Les solutions possibles}
\noindent
Dans cette section on va explorer les solutions potentielles qu'on peut adopter pour notre projet tel que les différentes techniques de recherches et les bases de données qu'on peut utiliser. 

\subsection{Recherche Régulière}
\noindent
Nous aurions pu utiliser la recherche régulière simplement en faisant correspondre le terme de recherche avec les phrases disponibles dans notre base de données SQL déja existante via des requêtes SQL beaucoup plus optimisés et rapides. Avec cette approche, il y a moins de travail et complexité, mais des résultats beaucoup moins précis.

\subsection{Utilisaton de base de donnèes Cassandra}
\noindent
Nous aurions pu utiliser une différente base de données SQL plus optimisée et performante comme Cassandra pour l'optimisation de vitesse de recherche et la précision des resultats renvoyès. Avec cette approche la migration des données existantes va être beaucoup plus complexe aussi que l'intégration de cette base de donnèes dans notre application. Mais les rèsultats vont être plus précis et rapides, mais il reste la limitation la plus importante, qui est la recherche en arabe avec le dialecte tunisien, et l'arabe traditionnel. Pour cette raison on a dècidè de prendre l'approche d'Elasticsearch avec la recherche vectorielle qui sont dans les sections ci-dessous.

\section{Choix d'approche de Recherche Vectorielle}
\noindent
En raison des défauts des autres solutions que nous avons mentionnées dans la section précédente, nous avons décidé d'opter pour l'approche de recherche vectorielle, que nous expliquerons plus en détail dans la section suivante.

\section{Recherche Vectorielle}
\noindent
La recherche vectorielle est une approche de la récupération des informations qui prend en charge l’indexation et l’exécution des requêtes sur des représentations numériques du contenu. Étant donné que le contenu est numérique plutôt que texte brut, la correspondance est basée sur des vecteurs qui sont les plus similaires au vecteur de requête, ce qui permet la correspondance entre :
\begin{itemize}
    \item La ressemblance sémantique ou conceptuelle (« chien » et « canine », conceptuellement similaire mais linguistiquement distincte)
    
    \item contenu multilingue (« dog » en anglais et « chien » en français)
\end{itemize}

\noindent
Pour calculer cette similarité il y a plusieurs approches de calcul, la plus significante, précis et populaire c'est la similarité cosinus qui utilise cette formule mathématique:
\[\cos(\theta) = \frac{\mathbf{A} \cdot \mathbf{B}}{\|\mathbf{A}\|\|\mathbf{B}\|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}
\]
Soit $A$ et $B$ deux vecteurs de n'importe quelles dimensions, la similarité cosinus mesure l'angle entre deux vecteurs. Plus l'angle est petit, plus les vecteurs sont similaires, le cosinus de leur angle $\theta$ s'obtient en prenant leur produit scalaire divisé par le produit de leurs normes. La valeur de cette angle est comprise entire [-1, 1], la valeur de -1 indique des vecteurs opposés, la valeur de 0 des vecteurs indépendants (orthogonaux) et la valeur de 1 des vecteurs colinéaires de coefficient positif. Plus que cette valeur s'approche de 1, plus que les deux vecteurs sont similaires.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/cosine.png}
\caption{Présentation du similarité cosinus}
\label{fig:cosine}
\end{figure}

\noindent
Comme la figure ~\ref{fig:fullprocess} montre, d'abord le client va saisir son terme de recherche (mot clé) qui est ensuite envoyé à notre contrôleur ASP .NET Core, qui ensuite envoie ce mot ou phrase à notre microservice en Flask qui contient notre modèle Sentence-Transformers(all-mpnet-base-v2) dans notre cas, qui ensuite verifie si le mot est en français, si c'est le cas, en fait l'encodage de phrase directe, sinon, en la traduit soit en utilisant Google Traduction si la phrase est en arabe traditionnel, soit en utilisant notre dictionnaire propre des mots du dialecte tunsienne et aprés avoir faire l'encodage, enfin, le vecteur est renvoyé au contrôleur, qui l'utilise pour faire la recherche vectorielle dans Elasticsearch, et renvoyer les résultats, qui sont les produits dans notre cas.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/fullprocess.png}
\caption{Présentation du processus de recherche avec recherche vectorielle}
\label{fig:fullprocess}
\end{figure}



\section{Elasticsearch}
\noindent
Elasticsearch est un outil d'analyse de données distribuèes open source et hautement èvolutif. Il est conçu pour stocker, rechercher, analyser et rechercher de grandes volumes de données de manière rapide et efficace en utilisant des diffèrentes mèthodes comme Knn Search.
Il utilise une structure de données de type index inversé pour indexer et rechercher rapidement des documents. Il prend en charge une variété de types de données, notamment le texte, les nombres, les dates, et les vecteurs par exemple le type dense vector. Avec tout ça, Elasticsearch facilite et optimise la recherche sémantique(vectorielle) en utilisant des indices inversés qui nous permettent de stocker des données de type dense vector (vecteur), qui sont extrêmement efficaces pour la recherche de texte complet. Au lieu de parcourir chaque document et de vérifier la correspondance avec les termes de la requête, Elasticsearch utilise cet indice inversé pour trouver rapidement les documents contenant les termes de recherche. Cela accélère considérablement le processus de recherche, car l'indice fonctionne comme un système de référence rapide.

\section{Utilisation d'un modèle Sentence-Transformers}
\noindent
Notre modèle de choix est un modèle appelé << all-mpnet-base-v2 >> qui est basé sur le modèle mpnet-base de Microsoft, et puisqu'il est déja pré-entraînée pour comprendre la langue française, il sert à convertir des phrases et des paragraphes en vecteurs sémantiques de 768 dimensions dans un espace vectoriel, avec une limite des paragraphes de 384 mots au maximum. Il est spécifiquement affiné pour établir des correspondances sémantiques précises entre les phrases en les plaçant dans un espace où la similarité cosinus peut être calculée efficacement pour des tâches comme la recherche sémantique, et la mesure de la similarité des phrases. \\
\citetitle{pinecone:mpnet} (\cite{pinecone:mpnet})

\subsection{Comment le modèle interprète les phrases?}
\noindent
Pour interpréter les phrases, le modèle a besoin d'un << Tokenizer >> puisqu'il ne peut pas comprendre le texte, on doit convertir chaque phrase en une représentation numérique. Le processus est appelé la << tokenisation >> qui est le processus de conversion d'une séquence de caractères en une séquence de jetons(tokens). En PNL, un jeton(token) représente généralement un mot, mais il peut également représenter des sous-mots, des caractères ou d'autres unités, selon le tokeniseur. Ce processus est nécessaire car notre modèle ne peut pas comprendre le texte brut. Au lieu de cela, il travail avec des représentations numériques de jetons. La figure ~\ref{fig:paddingexplanation} présente le processus de tokenisation.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/paddingexplanation.png}
\caption{Présentation du processus de tokenisation}
\label{fig:paddingexplanation}
\end{figure}

\noindent
La figure ~\ref{fig:padding} présente un exemple du processus de tokenisation.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/padding.png}
\caption{Exemple du processus de tokenisation}
\label{fig:padding}
\end{figure}

\newpage
\noindent
{\small\textbf{\textit{a. Padding }}}\mbox{}\\
Le remplissage(padding) est appliqué pour garantir que toutes les séquences d'un lot ont la même longueur, ce qui est une exigence pour de nombreuses architectures de réseaux neuronaux. Des jetons de remplissage sont ajoutés à la fin de la séquence pour étendre sa longueur jusqu'à un maximum prédéfini, qui est de 384 dans notre cas.

\noindent
{\small\textbf{\textit{b. Attention Mask (Masque d'attention) }}}\mbox{}\\
C'est simplement un masque qui fait la différence entre le contenu et les jetons de remplissage.

\noindent
{\small\textbf{\textit{c. Mean Pooling (Regroupement des moyennes) }}}\mbox{}\\
C'est un processus qui calcule efficacement la moyenne de la sequence obtenu aprés le padding tout en ignorant les jetons de remplissage (padding tokens) qui ont une valeur de 0, ce qui donne un seul vecteur d'intégration qui représente la phrase entière.
Ce processus ne prend en compte que les jetons sans remplissage dans la phrase, en utilisant un masque d'attention. Le masque d'attention a la même longueur que la séquence de jetons, « 1 » indiquant les jetons sans remplissage et « 0 » pour les jetons de remplissage. Cela garantit que l'incorporation de phrase résultante est calculée uniquement à partir du contenu significatif de la séquence. La figure ~\ref{fig:meanpooling} présente ce processus.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/mean_pooling.png}
\caption{Présentation du processus de Mean Pooling}
\label{fig:meanpooling}
\end{figure}

\subsection{Pourquoi utiliser Mean Pooling plutôt qu'un autre type de pooling?}
\noindent
Puisque notre modèle génère un vecteur pour chaque token aprés les étapes précédentes, le mean pooling consiste à prendre la moyenne de ces vecteurs sur tous les tokens, ce qui résulte en un unique vecteur qui est censé capturer l'essence sémantique de l'ensemble de la phrase, et donner importance à tous les mots de phrase, tous en nous permettant de prendre et interpréter le contexte de toute la phrase. Il existe deux autres types do pooling qu'on a testé sans obtenir de résultats aussi bons:

\noindent
{\small\textbf{\textit{a. Max Pooling }}}\mbox{}\\
Ce processus consiste à prendre la valeur maximum de ces vecteurs sur tous les tokens au lieu de la moyenne. Le problème avec cette stratégie est qu'elle peut donner plus importance à un mot ou phrase plus que les autres et alterner les résultats de manière négative, ce qui entraîne moins de précision. Par exemple, si une personne cherche un << T-shirt bleu >>, avec le max pooling, le mot << bleu >> peut avoir plus d'importance que t-shirt, donc il peut retourner tous les produits bleus, au lieu des t-shirts. La figure ~\ref{fig:maxpooling} présente ce processus. 

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/max_pooling.png}
\caption{Présentation du processus de Max Pooling}
\label{fig:maxpooling}
\end{figure}

\newpage
\noindent
{\small\textbf{\textit{b. Min Pooling }}}\mbox{}\\
Ce processus consiste à prendre la valeur minimum de ces vecteurs sur tous les tokens au lieu de la moyenne. Le problème avec cette stratégie est qu'elle peut donner moins importance à un mot ou phrase clé moins que les autres et alterner les résultats de manière négative, ce qui aussi entraîne moins de précision. Prenant le même exemple précédent, si une personne cherche un << T-shirt bleu >>, avec le min pooling, le mot << bleu >> peut avoir moins d'importance que t-shirt, donc il peut retourner tous les t-shirts sauf les bleus. La figure ~\ref{fig:minpooling} présente ce processus. 

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{logos/min_pooling.png}
\caption{Présentation du processus de Min Pooling}
\label{fig:minpooling}
\end{figure}


\section{Conclusion}
\noindent
Dans ce chapitre on a presenté et expliqué les approches qu'on a décidé de prendre ainsi que les technologies qu'on a utilisé et leur importances, pertinence et les benéfices qu'elles apportent à notre projet tels que la Recherche Vectorielle, l'Elasticsearch et le modèle sentence-transformers.